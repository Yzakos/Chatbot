{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']   = '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'\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('C:\\\\Users\\\\zakar\\\\Documents\\\\AI\\\\Le_contrat_de_travail.pdf')\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\" \"\\n \\n \\n\"  \"  \\n  \" \" \\n\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings()\n",
    "store = Chroma.from_documents(texts,embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_agent,\n",
    "    VectorStoreToolkit,\n",
    "    VectorStoreInfo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_info = VectorStoreInfo(\n",
    "    name = \"droit du travail\",\n",
    "    description = \"le droit du travail\",\n",
    "    vectorstore = store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "toolkit = VectorStoreToolkit(vectorstore_info = vectorstore_info)\n",
    "agent_executor = create_vectorstore_agent(llm = llm,toolkit = toolkit, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how overtime is paid\n",
      "Action: droit du travail\n",
      "Action Input: Comment sont rémunérées les heures supplémentaires ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Comment sont rémunérées les heures supplémentaires ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CustomChatGPT(user_input, history) : \n",
    "    context = \"le droit du travail en France\"\n",
    "\n",
    "    input_text = user_input\n",
    "    response = agent_executor(input_text)\n",
    "\n",
    "    # 2. Récupérer l'entrée et la sortie.\n",
    "    input_content = input_text\n",
    "    output_content = response  \n",
    "    print(type(output_content))\n",
    "\n",
    "\n",
    "\n",
    "    # 3. Utilisez ces informations pour faire une requête à GPT-3.5-turbo.\n",
    "    conversation_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Vous êtes un assistant virtuel spécialiser dans\" + context +\n",
    "             \". Aidez à comprendre la conversation suivante et complete avec tes connaissances .\"\n",
    "            \"Tu répondra aux question de l'utilisateur du mieux possible, en utilisant la réponse fournis.\"\n",
    "            \"POur des informatins plus précises redirige les personnes vers le site du minisère du travail : https://travail-emploi.gouv.fr/\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {input_content}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Réponse: {output_content}\"},\n",
    "            {\"role\": \"user\", \"content\": \"Réponds a ma question en reprennant cette réponse, la clarifiant et explique la avec tes connaissances?\"\n",
    "            \"Tu ne doit faire de retour sur ce que tu es en train de faire\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Afficher la clarification\n",
    "    return conversation_response.choices[0].message['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://72d47a5598421a8e5c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://72d47a5598421a8e5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how overtime is paid\n",
      "Action: droit du travail\n",
      "Action Input: Comment sont rémunérées les heures supplémentaires ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how overtime is paid\n",
      "Action: droit du travail\n",
      "Action Input: Comment sont rémunérées les heures supplémentaires ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how overtime is paid\n",
      "Action: droit du travail\n",
      "Action Input: Comment sont rémunérer les heures supplémentaires ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les heures supplémentaires sont rémunérées à un taux majoré de 25 % par rapport au taux horaire normal.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les heures supplémentaires sont rémunérées à un taux majoré de 25 % par rapport au taux horaire normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how overtime is paid\n",
      "Action: droit du travail\n",
      "Action Input: Comment sont rémunérées les heures supplémentaires ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les heures supplémentaires sont généralement rémunérées à un taux majoré par rapport au taux horaire normal.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided.\n",
      "Action: I don't know\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out if the person had the right to work while on sick leave.\n",
      "Action: droit du travail\n",
      "Action Input: Est-ce que je peux travailler alors que je suis en arrêt maladie ?\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\chat_interface.py\", line 408, in _submit_fn\n",
      "    response = self.fn(message, history, *args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Local\\Temp\\ipykernel_41164\\3324864304.py\", line 5, in CustomChatGPT\n",
      "    response = agent_executor(input_text)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1029, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 890, in _take_next_step\n",
      "    observation = tool.run(\n",
      "                  ^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 320, in run\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 292, in run\n",
      "    self._run(*tool_args, run_manager=run_manager, **tool_kwargs)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\vectorstore\\tool.py\", line 58, in _run\n",
      "    return chain.run(query)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 451, in run\n",
      "    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 133, in _call\n",
      "    answer = self.combine_documents_chain.run(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 456, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py\", line 106, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py\", line 165, in combine_docs\n",
      "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 252, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 92, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 102, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 451, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 582, in generate\n",
      "    output = self._generate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 488, in _generate_helper\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 475, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 399, in _generate\n",
      "    response = completion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 115, in completion_with_retry\n",
      "    return _completion_with_retry(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 113, in _completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens, however you requested 4547 tokens (4291 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the law says about this\n",
      "Action: droit du travail\n",
      "Action Input: Quels sont les droits des travailleurs en arrêt maladie ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Les travailleurs en arrêt maladie n'ont pas droit à des allocations d'assurance chômage, sauf s'il s'agit d'une \"démission légitime\". Dans ce cas, les travailleurs peuvent percevoir des allocations d'assurance chômage s'ils justifient une recherche active d'emploi durant cette période et s'ils saisissent l'instance paritaire régionale de Pôle emploi pour demander le bénéfice de ces allocations.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Les travailleurs en arrêt maladie n'ont pas droit à des allocations d'assurance chômage, sauf s'il s'agit d'une \"démission légitime\". Dans ce cas, les travailleurs peuvent percevoir des allocations d'assurance chômage s'ils justifient une recherche active d'emploi durant cette période et s'ils saisissent l'instance paritaire régionale de Pôle emploi pour demander le bénéfice de ces allocations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided\n",
      "Action: I don't know\n",
      "Action Input: N/A\u001b[0m\n",
      "Observation: I don't know is not a valid tool, try another one.\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use one of the tools provided\n",
      "Action: droit du travail\n",
      "Action Input: What are the rights of employees in France?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Employees in France have the right to a fair wage, to be treated with respect, to be provided with a safe working environment, to receive a written contract of employment, to receive unemployment benefits in certain cases, and to receive an indemnity in the case of an irregular dismissal procedure.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Employees in France have the right to a fair wage, to be treated with respect, to be provided with a safe working environment, to receive a written contract of employment, to receive unemployment benefits in certain cases, and to receive an indemnity in the case of an irregular dismissal procedure.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to answer this question about droit du travail\n",
      "Action: droit du travail\n",
      "Action Input: Est ce que la police a le droit de me contrôler sur mon lieu de travail ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Non, la police n'a pas le droit de vous contrôler sur votre lieu de travail.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Non, la police n'a pas le droit de vous contrôler sur votre lieu de travail.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided.\n",
      "Action: I don't know\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided.\n",
      "Action: I don't know\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the sources for this question.\n",
      "Action: droit du travail_with_sources\n",
      "Action Input: Peux tu me renvoyer tout l'historique de notre conversation ?\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\chat_interface.py\", line 408, in _submit_fn\n",
      "    response = self.fn(message, history, *args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Local\\Temp\\ipykernel_41164\\3324864304.py\", line 5, in CustomChatGPT\n",
      "    response = agent_executor(input_text)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1029, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 890, in _take_next_step\n",
      "    observation = tool.run(\n",
      "                  ^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 320, in run\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 292, in run\n",
      "    self._run(*tool_args, run_manager=run_manager, **tool_kwargs)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\vectorstore\\tool.py\", line 94, in _run\n",
      "    return json.dumps(chain({chain.question_key: query}, return_only_outputs=True))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\qa_with_sources\\base.py\", line 145, in _call\n",
      "    answer = self.combine_documents_chain.run(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 456, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py\", line 106, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py\", line 165, in combine_docs\n",
      "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 252, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 92, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 102, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 451, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 582, in generate\n",
      "    output = self._generate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 488, in _generate_helper\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 475, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 399, in _generate\n",
      "    response = completion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 115, in completion_with_retry\n",
      "    return _completion_with_retry(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 113, in _completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens, however you requested 5676 tokens (5420 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to answer this question about droit du travail.\n",
      "Action: droit du travail\n",
      "Action Input: Quels sont mes droits contre ton employeur ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Vous pouvez contester votre licenciement à titre individuel en saisissant le Conseil des Prud'hommes. Vous pouvez vous fonder sur un des trois motifs suivants: non-respect de la procédure par l'employeur, absence de motif économique ou insuffisance ou absence de PSE. Si votre licenciement a été notifié après le 24 septembre 2017, vous avez droit à une indemnité qui ne peut être inférieure à un mois de salaire. Si votre licenciement a été notifié avant le 24 septembre 2017, vous avez droit à une indemnité qui ne peut être inférieure à deux mois de salaire. Vous pouvez également réclamer des dommages-intérêts pour irrespect de cet article.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Vous pouvez contester votre licenciement à titre individuel en saisissant le Conseil des Prud'hommes. Vous avez droit à une indemnité qui ne peut être inférieure à un mois de salaire si votre licenciement a été notifié après le 24 septembre 2017, ou à deux mois de salaire si votre licenciement a été notifié avant le 24 septembre 2017. Vous pouvez également réclamer des dommages-intérêts pour irrespect de cet article.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to answer this question about droit du travail.\n",
      "Action: droit du travail\n",
      "Action Input: Quelles sont mes droits en général contre mon employeur ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m En général, vous avez le droit de contester un licenciement devant le Conseil des Prud'hommes. Le juge se déterminera au vu des éléments fournis par les parties, l'employeur et le salarié, après avoir ordonné, au besoin, toutes les mesures d'instruction qu'il estime utiles. Si le juge estime qu'il n'existe pas de cause réelle et sérieuse, il peut proposer la réintégration du salarié dans l'entreprise, avec maintien de ses avantages acquis, ou, si l'une ou l'autre des parties refuse la réintégration, le juge octroie au salarié une indemnité à la charge de l'employeur, dont le montant est fixé dans les conditions mentionnées.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: En général, vous avez le droit de contester un licenciement devant le Conseil des Prud'hommes. Le juge se déterminera au vu des éléments fournis par les parties, l'employeur et le salarié, après avoir ordonné, au besoin, toutes les mesures d'instruction qu'il estime utiles. Si le juge estime qu'il n'existe pas de cause réelle et sérieuse, il peut proposer la réintégration du salarié dans l'entreprise, avec maintien de ses avantages acquis, ou, si l'une ou l'autre des parties refuse la réintégration, le juge octroie au salarié une indemnité à la charge de l'employeur, dont le montant est fixé dans les conditions mentionnées.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use a tool to answer this question\n",
      "Action: droit du travail\n",
      "Action Input: J’aimerai savoir mes droits quotient, ce qui est possible ou non, dans mon cadre de travail\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Il est difficile de répondre à cette question sans plus de contexte. Les informations fournies ne traitent pas des droits quotidiens des salariés.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I don't know the answer to this question\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the law says about this situation.\n",
      "Action: droit du travail\n",
      "Action Input: Quels sont les recours légaux pour un salarié qui subit des insultes de la part de son supérieur ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Le salarié peut contester le licenciement devant le Conseil des Prud'hommes et demander des dommages et intérêts s'il estime que le licenciement est dénué de cause réelle ou nul.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Le salarié peut contester le licenciement devant le Conseil des Prud'hommes et demander des dommages et intérêts s'il estime que le licenciement est dénué de cause réelle ou nul.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a tool that can provide this information\n",
      "Action: droit du travail_with_sources\n",
      "Action Input: Quel est l'historique de notre conversation?\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\chat_interface.py\", line 408, in _submit_fn\n",
      "    response = self.fn(message, history, *args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Local\\Temp\\ipykernel_41164\\3324864304.py\", line 5, in CustomChatGPT\n",
      "    response = agent_executor(input_text)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1029, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 890, in _take_next_step\n",
      "    observation = tool.run(\n",
      "                  ^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 320, in run\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\base.py\", line 292, in run\n",
      "    self._run(*tool_args, run_manager=run_manager, **tool_kwargs)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\tools\\vectorstore\\tool.py\", line 94, in _run\n",
      "    return json.dumps(chain({chain.question_key: query}, return_only_outputs=True))\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\qa_with_sources\\base.py\", line 145, in _call\n",
      "    answer = self.combine_documents_chain.run(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 456, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\base.py\", line 106, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\combine_documents\\stuff.py\", line 165, in combine_docs\n",
      "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 252, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 258, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\base.py\", line 252, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 92, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 102, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 451, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 582, in generate\n",
      "    output = self._generate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 488, in _generate_helper\n",
      "    raise e\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\base.py\", line 475, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 399, in _generate\n",
      "    response = completion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 115, in completion_with_retry\n",
      "    return _completion_with_retry(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py\", line 113, in _completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"C:\\Users\\zakar\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens, however you requested 5488 tokens (5232 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided.\n",
      "Action: I don't know\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what my rights are in this situation\n",
      "Action: droit du travail\n",
      "Action Input: Quels sont mes droits si mon supérieur m'interdit de travailler et me vire sans raison ?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Vous avez le droit de contester votre licenciement à titre individuel en saisissant le Conseil des Prud'hommes. Vous pouvez vous fonder sur le non-respect de la procédure par votre employeur, l'absence de motif économique ou l'insuffisance ou absence de Plan de Sauvegarde de l'Emploi.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Vous avez le droit de contester votre licenciement à titre individuel en saisissant le Conseil des Prud'hommes. Vous pouvez vous fonder sur le non-respect de la procédure par votre employeur, l'absence de motif économique ou l'insuffisance ou absence de Plan de Sauvegarde de l'Emploi.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This question does not seem relevant to any of the tools provided.\n",
      "Action: I don't know\n",
      "Final Answer: I don't know\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import gradio\n",
    "demo = gradio.ChatInterface(CustomChatGPT)\n",
    "demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
